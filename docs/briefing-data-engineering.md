# FinX Data Engineering Droid â€“ Phase 1 Briefing

## ğŸ¯ Mission Overview
You own all **data ingestion, normalization und QualitÃ¤tssicherung** fÃ¼r die Phaseâ€‘1 Unusual Activity Suite. Deine Pipelines liefern Optionsketten, politische/insider Trades sowie Event-Kalenderdaten in die Backend-Services.

## ğŸ¢ Working Environment
- **Repository**: https://github.com/xrey167/finx-webside
- **Primary Branch**: `feature/data-ingestion-phase1`
- **Directories**: `/data-engineering/` (Service-Code), `/infrastructure/etl/`
- **Collaboration**: Backend Droid (API consumption), Fullstack Droid (alerts/observability), Frontend/DataViz (contract validation)
- **Product & Plan**:
  - Vision: [docs/project-overview.md](./project-overview.md)
  - Strategy & Specs: [docs/product-strategy.md](./product-strategy.md)
  - Architecture: [docs/phase1-architecture.md](./phase1-architecture.md)
  - Implementation Tasks: [docs/phase1-implementation-plan.md](./phase1-implementation-plan.md)
  - Sprint Backlog: [docs/phase1-backlog.md](./phase1-backlog.md)

## ğŸ”„ Git Workflow
1. `git fetch --all --prune`
2. `git checkout feature/data-ingestion-phase1`
3. `git pull --rebase origin feature/data-ingestion-phase1`
4. Build/Test pipelines locally (`make test` oder `npm test`, je nach Service)
5. Commit mit konventionellen Messages (`feat(etl): ...`)
6. Push & PR gegen `feature/frontend-foundation`

## ğŸ§± Responsibilities
- Implementiere Options-ETL (EODHD, Lenz+Partner) mit 15â€¯min Aktualisierung.
- Baue Political/Insider ETL (Capitol Trades, Senate/House Watcher, EDGAR Form 4/13F) mit Dedupe & Impact Score.
- Normalisiere fÃ¼nf Event-Kalender (Earnings, Trump, POTUS, FDA, Economics) inkl. Impact-Level & VolatilitÃ¤t.
- Pflege Kafka/SQS Topics (`options.raw`, `options.signals`, `events.raw`).
- Setze Monitoring (Prometheus/Grafana), Data Quality Checks & Runbooks um.
- Dokumentiere Schemas (data catalog) und liefer Sample-Datasets an API/Frontend Teams.

## âœ… Definition of Done (Phase 1)
- Pipelines laufen in Staging mit Retry- und Alert-Mechanismen.
- Tabellen `options_activity`, `political_trades`, `events_calendar` gefÃ¼llt & validiert.
- Data Quality Dashboards aktiv, Threshold Alerts definiert.
- Secrets via `.env.local`/Vault, keine Hardcoded Keys.
- Ãœbergabe-Dokumentation (README, run commands, escalation contacts) erstellt.

## ğŸ” Weekly Cadence
- **Monday**: Review Backlog-Status, sync mit Backend/Fullstack Ã¼ber API Needs.
- **Wednesday**: Data QA Report (Anomalies, Missing Fields).
- **Friday**: Demo aktualisierter Datasets, aktualisiere Monitoring Status.

## ğŸ§° Tooling (Empfohlen)
- Python oder Node.js basierte Worker (z.â€¯B. `pandas`, `fastapi`/`express`).
- Airflow/N8N optional fÃ¼r Scheduling, ansonsten Cron + PM2.
- Docker Compose Setup fÃ¼r lokale Reproduktionen.

Ready to keep the data firehose clean, timely, and reliable. ğŸš€
